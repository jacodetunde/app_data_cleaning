{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# import pyarrow as pa\n",
    "# import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "\n",
    "# # Get a list of all CSV files in a directory\n",
    "# csv_files = glob.glob('data/*.csv')\n",
    "\n",
    "# # Create an empty list to store the dataframes\n",
    "# dfs = []\n",
    "\n",
    "# # Loop through the CSV files and read them into Pandas dataframes\n",
    "# for file in csv_files:\n",
    "#     df = pd.read_csv(file,encoding='latin-1')\n",
    "#     dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "df1 = pd.read_csv(\"data/KJV_Bible.csv\")\n",
    "df2 =pd.read_csv(\"data/ASV_Bible.csv\")\n",
    "df3 =pd.read_csv(\"data/t_bbe.csv\")\n",
    "df4 =pd.read_csv(\"data/t_dby.csv\",encoding='latin-1')\n",
    "df5 =pd.read_csv(\"data/t_web.csv\")\n",
    "df6 =pd.read_csv(\"data/YLT_Bible.csv\")\n",
    "df7 =pd.read_csv(\"data/t_wbt.csv\")\n",
    "df8 = pd.read_csv('data/cross_references.txt',delimiter = \"\\t\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs1 = pd.read_csv(\"resources/bible_version_key.csv\")\n",
    "# vs = vs1.to_parquet('resources/bible_version_key.parquet',engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>verse</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001001</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "      <td>Moses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001002</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>And the earth was without form, and void; and ...</td>\n",
       "      <td>Moses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001003</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>And God said, Let there be light: and there wa...</td>\n",
       "      <td>Moses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001004</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>And God saw the light, that it was good: and G...</td>\n",
       "      <td>Moses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001005</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>And God called the light Day, and the darkness...</td>\n",
       "      <td>Moses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     book  chapter  verse  \\\n",
       "0  1001001  Genesis        1      1   \n",
       "1  1001002  Genesis        1      2   \n",
       "2  1001003  Genesis        1      3   \n",
       "3  1001004  Genesis        1      4   \n",
       "4  1001005  Genesis        1      5   \n",
       "\n",
       "                                                text author  \n",
       "0  In the beginning God created the heaven and th...  Moses  \n",
       "1  And the earth was without form, and void; and ...  Moses  \n",
       "2  And God said, Let there be light: and there wa...  Moses  \n",
       "3  And God saw the light, that it was good: and G...  Moses  \n",
       "4  And God called the light Day, and the darkness...  Moses  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing unnecessary columns\n",
    "df1 = df1.drop(['Unnamed: 0'],axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting kjv to df1\n",
    "kjv_df = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming bible books\n",
    "kjv_df['book'] = kjv_df['book'].replace(['1 Samuel (1 Kings)','2 Samuel (2 Kings)','1 Kings (3 Kings)','2 Kings (4 Kings)',\n",
    "                                'Song of Solomon (Canticles)'],['1 Samuel','2 Samuel','1 Kings','2 Kings','Song of Solomon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to clean the data\n",
    "def clean(df):\n",
    "    dt = {'b':list(range(1, 67)),\n",
    "        'book': kjv_df['book'].unique().tolist()}\n",
    "    dt_df = pd.DataFrame(dt)\n",
    "    df = pd.merge(df,dt_df,how='left',on='b')\n",
    "    df = df[['id','book','c','v','t']]\n",
    "    df = df.rename(columns={'c':'chapter','v':'verse','t':'text'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function to all bible version\n",
    "asv_df = clean(df=df2)\n",
    "bbe_df = clean(df=df3)\n",
    "dby_df =clean(df=df4)\n",
    "web_df = clean(df=df5)\n",
    "ylt_df =clean(df=df6)\n",
    "wbt_df =clean(df=df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343609, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning cross reference data\n",
    "df8 =pd.read_csv('data/cross_references.txt',delimiter = \"\\t\",low_memory=False)\n",
    "df8 = df8.rename(columns={'To Verse':'ToVerse'})\n",
    "df8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431543, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Further cleaning of cross reference data. i.e breaking out cross reference with extended verses\n",
    "df_08 = (df8.set_index(df8.columns.drop('ToVerse',1).tolist()).ToVerse.str.split('-', \n",
    "            expand=True).stack().reset_index().rename(columns={0:'ToVerse'}).loc[:, df8.columns])\n",
    "df_08.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further cleaning of cross references\n",
    "votes = df_08[['Votes']]\n",
    "base = df_08['From Verse'].str.split(\".\", expand = True)\n",
    "base = base.rename(columns={0:'Abv',1:'chapter',2:'verse'})\n",
    "# base = pd.concat([base,votes],axis=1)\n",
    "ref =df_08['ToVerse'].str.split(\".\", expand = True)\n",
    "ref = ref.rename(columns={0:'Abv',1:'chapter',2:'verse'})\n",
    "ref = pd.concat([ref,votes],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431543, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431543, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe to join abbreviation to all the translations\n",
    "data = {'Abv':base.Abv.unique().tolist(),\n",
    "        'book': df1.book.unique().tolist()}\n",
    "abv_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a merging functions for all the translations\n",
    "def abbrevation(k):\n",
    "    k = pd.merge(k,abv_df,on='book',how='left')\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv_k = abbrevation(k=kjv_df)\n",
    "abv_a = abbrevation(k=asv_df)\n",
    "abv_b = abbrevation(k=bbe_df)\n",
    "abv_d = abbrevation(k=dby_df)\n",
    "abv_w = abbrevation(k=web_df)\n",
    "abv_y =abbrevation(k=ylt_df)\n",
    "abv_wb = abbrevation(k=wbt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv_k['version'] = 'KJV'\n",
    "abv_a['version'] = 'ASV'\n",
    "abv_b['version'] = 'BBE'\n",
    "abv_d['version'] = 'DARBY'\n",
    "abv_w['version'] = 'WEB'\n",
    "abv_y['version'] = 'YLT'\n",
    "abv_wb['version'] = 'WBT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KJV'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tranl = abv_k['version'].values[0]\n",
    "tranl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write the clean data to csv file\n",
    "# abv_k.to_csv('resources/kjv.csv')\n",
    "# abv_a.to_csv('resources/asv.csv')\n",
    "# abv_b.to_csv('resources/bbe.csv')\n",
    "# abv_d.to_csv('resources/dby.csv')\n",
    "# abv_w.to_csv('resources/web.csv')\n",
    "# abv_y.to_csv('resources/ylt.csv')\n",
    "# abv_wb.to_csv('resources/wbt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abv_k.to_parquet('resources/kjv.parquet',engine='fastparquet')\n",
    "# abv_a.to_parquet('resources/asv.parquet',engine='fastparquet')\n",
    "# abv_b.to_parquet('resources/bbe.parquet',engine='fastparquet')\n",
    "# abv_d.to_parquet('resources/dby.parquet',engine='fastparquet')\n",
    "# abv_w.to_parquet('resources/web.parquet',engine='fastparquet')\n",
    "# abv_y.to_parquet('resources/ylt.parquet',engine='fastparquet')\n",
    "# abv_wb.to_parquet('resources/wbt.parquet',engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_parquet('resources/kjv.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that would merge text to base cross reference for all translations\n",
    "def base_merge(p):\n",
    "    base[['chapter','verse']] = base[['chapter','verse']].astype(int)\n",
    "    p= pd.merge(base,p,on=['Abv','chapter','verse'],how='left')\n",
    "    p = p[['id','Abv','book','chapter','verse','text']]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying merge functions to all translation for base scripture references\n",
    "base_k = base_merge(p=abv_k)\n",
    "base_a = base_merge(p=abv_a)\n",
    "base_b = base_merge(p=abv_b)\n",
    "base_d = base_merge(p=abv_d)\n",
    "base_w = base_merge(p=abv_w)\n",
    "base_y =base_merge(p=abv_y)\n",
    "base_wb = base_merge(p=abv_wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a merging functions for all cross references scriptures\n",
    "# def ref_merge(q):\n",
    "#     ref[['chapter','verse']] = ref[['chapter','verse']].astype(int)\n",
    "#     q= pd.merge(ref,q,on=['Abv','chapter','verse'],how='left')\n",
    "#     q = q.rename(columns={'Abv':'Abv_ref','book':'book_ref','chapter':'chapter_ref','verse':'verse_ref','text':'text_ref'})\n",
    "#     q = q[['id','Abv_ref','book_ref','chapter_ref','verse_ref','text_ref','Votes']]\n",
    "#     return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a merging functions for all cross references scriptures\n",
    "def ref_merge(q):\n",
    "    ref[['chapter','verse']] = ref[['chapter','verse']].astype(int)\n",
    "    q= pd.merge(ref,q,on=['Abv','chapter','verse'],how='left')\n",
    "    q = q.rename(columns={'id':'ref_id','Abv':'ref_Abv','book':'ref_book','chapter':'ref_chapter','verse':'ref_verse','text':'ref_text'})\n",
    "    q = q[['ref_id','ref_Abv','ref_book','ref_chapter','ref_verse','ref_text','Votes']]\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying merging function to all cross references\n",
    "ref_k = ref_merge(q=abv_k)\n",
    "ref_a = ref_merge(q=abv_a)\n",
    "ref_b = ref_merge(q=abv_b)\n",
    "ref_d = ref_merge(q=abv_d)\n",
    "ref_w = ref_merge(q=abv_w)\n",
    "ref_y =ref_merge(q=abv_y)\n",
    "ref_wb = ref_merge(q=abv_wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431596, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_wb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translations complete references\n",
    "kjv_ref = pd.concat([base_k,ref_k],axis=1)\n",
    "asv_ref = pd.concat([base_a,ref_a],axis=1)\n",
    "bbe_ref = pd.concat([base_b,ref_b],axis=1)\n",
    "dby_ref = pd.concat([base_d,ref_d],axis=1)\n",
    "web_ref = pd.concat([base_w,ref_w],axis=1)\n",
    "ylt_ref = pd.concat([base_y,ref_y],axis=1)\n",
    "wbt_ref = pd.concat([base_wb,ref_wb],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Abv</th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>verse</th>\n",
       "      <th>text</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>ref_Abv</th>\n",
       "      <th>ref_book</th>\n",
       "      <th>ref_chapter</th>\n",
       "      <th>ref_verse</th>\n",
       "      <th>ref_text</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001001</td>\n",
       "      <td>Gen</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "      <td>23065017</td>\n",
       "      <td>Isa</td>\n",
       "      <td>Isaiah</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>For, behold, I create new heavens and a new ea...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001001</td>\n",
       "      <td>Gen</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "      <td>19033006</td>\n",
       "      <td>Ps</td>\n",
       "      <td>Psalms</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>By the word of the LORD were the heavens made;...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001001</td>\n",
       "      <td>Gen</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "      <td>18038004</td>\n",
       "      <td>Job</td>\n",
       "      <td>Job</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>Where wast thou when I laid the foundations of...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001001</td>\n",
       "      <td>Gen</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "      <td>66022013</td>\n",
       "      <td>Rev</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>I am Alpha and Omega, the beginning and the en...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001001</td>\n",
       "      <td>Gen</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "      <td>66010006</td>\n",
       "      <td>Rev</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>And sware by him that liveth for ever and ever...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431538</th>\n",
       "      <td>66022021</td>\n",
       "      <td>Rev</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>The grace of our Lord Jesus Christ be with you...</td>\n",
       "      <td>45016020</td>\n",
       "      <td>Rom</td>\n",
       "      <td>Romans</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>And the God of peace shall bruise Satan under ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431539</th>\n",
       "      <td>66022021</td>\n",
       "      <td>Rev</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>The grace of our Lord Jesus Christ be with you...</td>\n",
       "      <td>53003018</td>\n",
       "      <td>2Thess</td>\n",
       "      <td>2 Thessalonians</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>The grace of our Lord Jesus Christ be with you...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431540</th>\n",
       "      <td>66022021</td>\n",
       "      <td>Rev</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>The grace of our Lord Jesus Christ be with you...</td>\n",
       "      <td>49006023</td>\n",
       "      <td>Eph</td>\n",
       "      <td>Ephesians</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>Peace be to the brethren, and love with faith,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431541</th>\n",
       "      <td>66022021</td>\n",
       "      <td>Rev</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>The grace of our Lord Jesus Christ be with you...</td>\n",
       "      <td>49006024</td>\n",
       "      <td>Eph</td>\n",
       "      <td>Ephesians</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>Grace be with all them that love our Lord Jesu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431542</th>\n",
       "      <td>66022021</td>\n",
       "      <td>Rev</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>The grace of our Lord Jesus Christ be with you...</td>\n",
       "      <td>47013014</td>\n",
       "      <td>2Cor</td>\n",
       "      <td>2 Corinthians</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>The grace of the Lord Jesus Christ, and the lo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>431543 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  Abv        book  chapter  verse  \\\n",
       "0        1001001  Gen     Genesis        1      1   \n",
       "1        1001001  Gen     Genesis        1      1   \n",
       "2        1001001  Gen     Genesis        1      1   \n",
       "3        1001001  Gen     Genesis        1      1   \n",
       "4        1001001  Gen     Genesis        1      1   \n",
       "...          ...  ...         ...      ...    ...   \n",
       "431538  66022021  Rev  Revelation       22     21   \n",
       "431539  66022021  Rev  Revelation       22     21   \n",
       "431540  66022021  Rev  Revelation       22     21   \n",
       "431541  66022021  Rev  Revelation       22     21   \n",
       "431542  66022021  Rev  Revelation       22     21   \n",
       "\n",
       "                                                     text    ref_id ref_Abv  \\\n",
       "0       In the beginning God created the heaven and th...  23065017     Isa   \n",
       "1       In the beginning God created the heaven and th...  19033006      Ps   \n",
       "2       In the beginning God created the heaven and th...  18038004     Job   \n",
       "3       In the beginning God created the heaven and th...  66022013     Rev   \n",
       "4       In the beginning God created the heaven and th...  66010006     Rev   \n",
       "...                                                   ...       ...     ...   \n",
       "431538  The grace of our Lord Jesus Christ be with you...  45016020     Rom   \n",
       "431539  The grace of our Lord Jesus Christ be with you...  53003018  2Thess   \n",
       "431540  The grace of our Lord Jesus Christ be with you...  49006023     Eph   \n",
       "431541  The grace of our Lord Jesus Christ be with you...  49006024     Eph   \n",
       "431542  The grace of our Lord Jesus Christ be with you...  47013014    2Cor   \n",
       "\n",
       "               ref_book  ref_chapter  ref_verse  \\\n",
       "0                Isaiah           65         17   \n",
       "1                Psalms           33          6   \n",
       "2                   Job           38          4   \n",
       "3            Revelation           22         13   \n",
       "4            Revelation           10          6   \n",
       "...                 ...          ...        ...   \n",
       "431538           Romans           16         20   \n",
       "431539  2 Thessalonians            3         18   \n",
       "431540        Ephesians            6         23   \n",
       "431541        Ephesians            6         24   \n",
       "431542    2 Corinthians           13         14   \n",
       "\n",
       "                                                 ref_text  Votes  \n",
       "0       For, behold, I create new heavens and a new ea...      6  \n",
       "1       By the word of the LORD were the heavens made;...     12  \n",
       "2       Where wast thou when I laid the foundations of...     35  \n",
       "3       I am Alpha and Omega, the beginning and the en...      3  \n",
       "4       And sware by him that liveth for ever and ever...     14  \n",
       "...                                                   ...    ...  \n",
       "431538  And the God of peace shall bruise Satan under ...      3  \n",
       "431539  The grace of our Lord Jesus Christ be with you...      4  \n",
       "431540  Peace be to the brethren, and love with faith,...      1  \n",
       "431541  Grace be with all them that love our Lord Jesu...      1  \n",
       "431542  The grace of the Lord Jesus Christ, and the lo...      2  \n",
       "\n",
       "[431543 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kjv_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kjv_ref.to_parquet('resources/kjv_ref.parquet',engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing cross reference to csv\n",
    "# kjv_ref.to_parquet('resources/kjv_ref.parquet',engine='fastparquet')\n",
    "# asv_ref.to_parquet('resources/asv_ref.parquet',engine='fastparquet')\n",
    "# bbe_ref.to_parquet('resources/bbe_ref.parquet',engine='fastparquet')\n",
    "# dby_ref.to_parquet('resources/dby_ref.parquet',engine='fastparquet')\n",
    "# web_ref.to_parquet('resources/web_ref.parquet',engine='fastparquet')\n",
    "# ylt_ref.to_parquet('resources/ylt_ref.parquet',engine='fastparquet')\n",
    "# wbt_ref.to_parquet('resources/wbt_ref.parquet',engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing cross reference to csv\n",
    "# kjv_ref.to_csv('resources/kjv_ref.csv')\n",
    "# asv_ref.to_csv('resources/asv_ref.csv')\n",
    "# bbe_ref.to_csv('resources/bbe_ref.csv')\n",
    "# dby_ref.to_csv('resources/dby_ref.csv')\n",
    "# web_ref.to_csv('resources/web_ref.csv')\n",
    "# ylt_ref.to_csv('resources/ylt_ref.csv')\n",
    "# wbt_ref.to_csv('resources/wbt_ref.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapters = df[df['book'] == book_name]['chapter'].unique()\n",
    "#     for chapter in chapters:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for book in abv_k['book']:\n",
    "#     for chapter in abv_k['chapter']:\n",
    "#         abv_k['chapter_texts'] = \" \".join(abv_k[(abv_k['book'] == book) & (abv_k['chapter'] == chapter)][\"text\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_concatenation(df):\n",
    "    # Creating a multi-index groupby object based on 'book' and 'chapter'\n",
    "    grouped = df.groupby(['book', 'chapter'])\n",
    "    \n",
    "    # Applying a join operation to concatenate texts within each group\n",
    "    chapter_texts = grouped['text'].apply(lambda texts: ' '.join(texts))\n",
    "\n",
    "    # Resetting index to turn the multi-index series into a DataFrame\n",
    "    result_df = chapter_texts.reset_index(name='chapter_texts')\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the function with the abv_k DataFrame\n",
    "abk_c = text_concatenation(abv_k)\n",
    "asv_c = text_concatenation(abv_a)\n",
    "bbe_c = text_concatenation(abv_b)\n",
    "dby_c = text_concatenation(abv_d)\n",
    "web_c = text_concatenation(abv_w)\n",
    "ylt_c = text_concatenation(abv_y)\n",
    "wbt_c = text_concatenation(abv_wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv_kc = pd.merge(abv_k, abk_c, on =['book', 'chapter'], how='left')\n",
    "abv_ac = pd.merge(abv_a, asv_c, on =['book', 'chapter'], how='left')\n",
    "abv_cc = pd.merge(abv_b, bbe_c, on =['book', 'chapter'], how='left')\n",
    "abv_dc = pd.merge(abv_d, dby_c, on =['book', 'chapter'], how='left')\n",
    "abv_wc = pd.merge(abv_w, web_c, on =['book', 'chapter'], how='left')\n",
    "abv_yc = pd.merge(abv_y, ylt_c, on =['book', 'chapter'], how='left')\n",
    "abv_wbc = pd.merge(abv_wb, wbt_c, on =['book', 'chapter'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>verse</th>\n",
       "      <th>text</th>\n",
       "      <th>Abv</th>\n",
       "      <th>version</th>\n",
       "      <th>chapter_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001001</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "      <td>Gen</td>\n",
       "      <td>WBT</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001002</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>And the earth was without form, and void; and ...</td>\n",
       "      <td>Gen</td>\n",
       "      <td>WBT</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001003</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>And God said, Let there be light: and there wa...</td>\n",
       "      <td>Gen</td>\n",
       "      <td>WBT</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001004</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>And God saw the light, that it was good: and G...</td>\n",
       "      <td>Gen</td>\n",
       "      <td>WBT</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001005</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>And God called the light Day, and the darkness...</td>\n",
       "      <td>Gen</td>\n",
       "      <td>WBT</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31101</th>\n",
       "      <td>66022017</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>And the Spirit and the bride say, Come. And le...</td>\n",
       "      <td>Rev</td>\n",
       "      <td>WBT</td>\n",
       "      <td>And he showed me a pure river of water of life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31102</th>\n",
       "      <td>66022018</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>For I testify to every man that heareth the wo...</td>\n",
       "      <td>Rev</td>\n",
       "      <td>WBT</td>\n",
       "      <td>And he showed me a pure river of water of life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31103</th>\n",
       "      <td>66022019</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>And if any man shall take away from the words ...</td>\n",
       "      <td>Rev</td>\n",
       "      <td>WBT</td>\n",
       "      <td>And he showed me a pure river of water of life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31104</th>\n",
       "      <td>66022020</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>He who testifieth these things saith, Surely I...</td>\n",
       "      <td>Rev</td>\n",
       "      <td>WBT</td>\n",
       "      <td>And he showed me a pure river of water of life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31105</th>\n",
       "      <td>66022021</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>The grace of our Lord Jesus Christ be with you...</td>\n",
       "      <td>Rev</td>\n",
       "      <td>WBT</td>\n",
       "      <td>And he showed me a pure river of water of life...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31106 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id        book  chapter  verse  \\\n",
       "0       1001001     Genesis        1      1   \n",
       "1       1001002     Genesis        1      2   \n",
       "2       1001003     Genesis        1      3   \n",
       "3       1001004     Genesis        1      4   \n",
       "4       1001005     Genesis        1      5   \n",
       "...         ...         ...      ...    ...   \n",
       "31101  66022017  Revelation       22     17   \n",
       "31102  66022018  Revelation       22     18   \n",
       "31103  66022019  Revelation       22     19   \n",
       "31104  66022020  Revelation       22     20   \n",
       "31105  66022021  Revelation       22     21   \n",
       "\n",
       "                                                    text  Abv version  \\\n",
       "0      In the beginning God created the heaven and th...  Gen     WBT   \n",
       "1      And the earth was without form, and void; and ...  Gen     WBT   \n",
       "2      And God said, Let there be light: and there wa...  Gen     WBT   \n",
       "3      And God saw the light, that it was good: and G...  Gen     WBT   \n",
       "4      And God called the light Day, and the darkness...  Gen     WBT   \n",
       "...                                                  ...  ...     ...   \n",
       "31101  And the Spirit and the bride say, Come. And le...  Rev     WBT   \n",
       "31102  For I testify to every man that heareth the wo...  Rev     WBT   \n",
       "31103  And if any man shall take away from the words ...  Rev     WBT   \n",
       "31104  He who testifieth these things saith, Surely I...  Rev     WBT   \n",
       "31105  The grace of our Lord Jesus Christ be with you...  Rev     WBT   \n",
       "\n",
       "                                           chapter_texts  \n",
       "0      In the beginning God created the heaven and th...  \n",
       "1      In the beginning God created the heaven and th...  \n",
       "2      In the beginning God created the heaven and th...  \n",
       "3      In the beginning God created the heaven and th...  \n",
       "4      In the beginning God created the heaven and th...  \n",
       "...                                                  ...  \n",
       "31101  And he showed me a pure river of water of life...  \n",
       "31102  And he showed me a pure river of water of life...  \n",
       "31103  And he showed me a pure river of water of life...  \n",
       "31104  And he showed me a pure river of water of life...  \n",
       "31105  And he showed me a pure river of water of life...  \n",
       "\n",
       "[31106 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abv_wbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_t5(text, max_length=50):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=5, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# summary = summarize_with_t5(your_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v9/2n54qmv52tv2gm21lxvx102m0000gn/T/ipykernel_4219/980768053.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mabv_kc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chapter_summary'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabv_kc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chapter_texts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msummarize_with_t5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1157\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/var/folders/v9/2n54qmv52tv2gm21lxvx102m0000gn/T/ipykernel_4219/980768053.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mabv_kc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chapter_summary'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabv_kc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chapter_texts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msummarize_with_t5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/v9/2n54qmv52tv2gm21lxvx102m0000gn/T/ipykernel_4219/776127436.py\u001b[0m in \u001b[0;36msummarize_with_t5\u001b[0;34m(text, max_length)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummarize_with_t5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"summarize: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msummary_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1795\u001b[0m             )\n\u001b[1;32m   1796\u001b[0m             \u001b[0;31m# 13. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1798\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3253\u001b[0m             )\n\u001b[1;32m   3254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past_key_values\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3255\u001b[0;31m                 model_kwargs[\"past_key_values\"] = self._temporary_reorder_cache(\n\u001b[0m\u001b[1;32m   3256\u001b[0m                     \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past_key_values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3257\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_temporary_reorder_cache\u001b[0;34m(self, past_key_values, beam_idx)\u001b[0m\n\u001b[1;32m   2964\u001b[0m         \u001b[0;31m# Exception 1: code path for models using the legacy cache format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2966\u001b[0;31m             \u001b[0mpast_key_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reorder_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2967\u001b[0m         \u001b[0;31m# Exception 2: models with different cache formats. These are limited to `DynamicCache` until their\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m         \u001b[0;31m# cache format is standardized, to avoid adding complexity to the codebase.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36m_reorder_cache\u001b[0;34m(self, past_key_values, beam_idx)\u001b[0m\n\u001b[1;32m   1851\u001b[0m                 \u001b[0;31m# need to set correct `past` for each of the four key / value states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m                 reordered_layer_past_states = reordered_layer_past_states + (\n\u001b[0;32m-> 1853\u001b[0;31m                     \u001b[0mlayer_past_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_past_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m                 )\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "abv_kc['chapter_summary'] = abv_kc['chapter_texts'].apply(lambda x: summarize_with_t5(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.t5.modeling_tf_t5 because of the following error (look up to see its traceback):\nmodule 'numpy' has no attribute 'typeDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/t5/modeling_tf_t5.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf2xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdynamic_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# from tensorflow.python import keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;31m# from tensorflow.python.layers import layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_tf_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0mHDF5_OBJECT_HEADER_LIMIT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/h5py/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_conv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_converters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_register_converters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0m_register_converters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pxd\u001b[0m in \u001b[0;36minit h5py._conv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pyx\u001b[0m in \u001b[0;36minit h5py.h5t\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# will increase the import time. See: #16679 for related discussion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0muse_hugepage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'typeDict'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v9/2n54qmv52tv2gm21lxvx102m0000gn/T/ipykernel_4219/1047885377.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFT5ForConditionalGeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m't5-small'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1385\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.t5.modeling_tf_t5 because of the following error (look up to see its traceback):\nmodule 'numpy' has no attribute 'typeDict'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
    "\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def batch_summarize_with_t5(texts, batch_size=10, max_length=50):\n",
    "    summaries = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_inputs = tokenizer.batch_encode_plus([\"summarize: \" + text for text in batch_texts], \n",
    "                                                   return_tensors=\"tf\", \n",
    "                                                   max_length=512, \n",
    "                                                   padding=True, \n",
    "                                                   truncation=True)\n",
    "\n",
    "        summary_ids = model.generate(batch_inputs['input_ids'], \n",
    "                                     max_length=max_length, \n",
    "                                     min_length=5, \n",
    "                                     length_penalty=2.0, \n",
    "                                     num_beams=4, \n",
    "                                     early_stopping=True)\n",
    "        \n",
    "        batch_summaries = [tokenizer.decode(ids, skip_special_tokens=True) for ids in summary_ids]\n",
    "        summaries.extend(batch_summaries)\n",
    "    return summaries\n",
    "\n",
    "# Assuming abv_kc is your DataFrame and 'chapter_texts' is the column with texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put the model on the GPU\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "def batch_summarize_with_t5(texts, batch_size=10, max_length=50):\n",
    "    summaries = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_inputs = tokenizer.batch_encode_plus(batch_texts, return_tensors=\"pt\", \n",
    "                                                   max_length=512, padding=True, truncation=True)\n",
    "\n",
    "        # If you have a GPU, send the inputs to the GPU\n",
    "        if torch.cuda.is_available():\n",
    "            batch_inputs = {k: v.cuda() for k, v in batch_inputs.items()}\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculation for inference\n",
    "            summary_ids = model.generate(**batch_inputs, \n",
    "                                         max_length=max_length, \n",
    "                                         min_length=5, \n",
    "                                         length_penalty=2.0, \n",
    "                                         num_beams=4, \n",
    "                                         early_stopping=True)\n",
    "        \n",
    "        batch_summaries = [tokenizer.decode(ids, skip_special_tokens=True) for ids in summary_ids]\n",
    "        summaries.extend(batch_summaries)\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v9/2n54qmv52tv2gm21lxvx102m0000gn/T/ipykernel_4219/441862893.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mabv_kc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chapter_summary'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_summarize_with_t5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabv_kc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chapter_texts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/v9/2n54qmv52tv2gm21lxvx102m0000gn/T/ipykernel_4219/3231694644.py\u001b[0m in \u001b[0;36mbatch_summarize_with_t5\u001b[0;34m(texts, batch_size, max_length)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Disable gradient calculation for inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             summary_ids = model.generate(**batch_inputs, \n\u001b[0m\u001b[1;32m     28\u001b[0m                                          \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                          \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1795\u001b[0m             )\n\u001b[1;32m   1796\u001b[0m             \u001b[0;31m# 13. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1798\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3190\u001b[0m                 \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# don't waste resources running the code we don't need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3192\u001b[0;31m             \u001b[0mnext_token_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3193\u001b[0m             next_token_scores = nn.functional.log_softmax(\n\u001b[1;32m   3194\u001b[0m                 \u001b[0mnext_token_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "abv_kc['chapter_summary'] = batch_summarize_with_t5(abv_kc['chapter_texts'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v9/2n54qmv52tv2gm21lxvx102m0000gn/T/ipykernel_4219/2671554913.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'docx' is not defined"
     ]
    }
   ],
   "source": [
    "docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "   \n",
    "# Input text - to summarize \n",
    "text = docx\n",
    "   \n",
    "# Tokenizing the text\n",
    "stopWords = set(stopwords.words(\"english\"))\n",
    "words = word_tokenize(text)\n",
    "   \n",
    "# Creating a frequency table to keep the \n",
    "# score of each word\n",
    "   \n",
    "freqTable = dict()\n",
    "for word in words:\n",
    "    word = word.lower()\n",
    "    if word in stopWords:\n",
    "        continue\n",
    "    if word in freqTable:\n",
    "        freqTable[word] += 1\n",
    "    else:\n",
    "        freqTable[word] = 1\n",
    "        \n",
    "#creating a dictionary to keep the score\n",
    "# of each sentence\n",
    "sentences = sent_tokenize(text)\n",
    "sentenceValue = dict()\n",
    "   \n",
    "for sentence in sentences:\n",
    "    for word, freq in freqTable.items():\n",
    "        if word in sentence.lower():\n",
    "            if sentence in sentenceValue:\n",
    "                sentenceValue[sentence] += freq\n",
    "            else:\n",
    "                sentenceValue[sentence] = freq\n",
    "   \n",
    "   \n",
    "\n",
    "sumValues = 0\n",
    "for sentence in sentenceValue:\n",
    "    sumValues += sentenceValue[sentence]\n",
    "\n",
    "#Average value of a sentence from the original text\n",
    "   \n",
    "average = int(sumValues / len(sentenceValue))\n",
    "   \n",
    "# Storing sentences into our summary.\n",
    "summary = ''\n",
    "for sentence in sentences:\n",
    "    if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
    "        summary += \" \" + sentence\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.lsa import LsaSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the text string using PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "parser=PlaintextParser.from_string(docx,Tokenizer('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the summarizer\n",
    "lsa_summarizer=LsaSummarizer()\n",
    "lsa_summary= lsa_summarizer(parser.document,10)\n",
    "\n",
    "# Printing the summary\n",
    "for sentence in lsa_summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sumy\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a summary of 3 sentences.\n",
    "my_parser = PlaintextParser.from_string(docx,Tokenizer('english'))\n",
    "lex_rank_summarizer = LexRankSummarizer()\n",
    "lexrank_summary = lex_rank_summarizer(my_parser.document,sentences_count=10)\n",
    "\n",
    "# Printing the summary\n",
    "for sentence in lexrank_summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import heapq\n",
    "\n",
    "def summarize(text, num_sentences=5):\n",
    "    nltk.download(\"punkt\")  # Download the required NLTK resource\n",
    "\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    # Compute the frequency of each word in the text\n",
    "    word_frequencies = {}\n",
    "    for sentence in sentences:\n",
    "        for word in nltk.word_tokenize(sentence.lower()):\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 0\n",
    "            word_frequencies[word] += 1\n",
    "\n",
    "    # Compute the weight of each sentence by summing the frequency of its words\n",
    "    sentence_weights = {}\n",
    "    for sentence in sentences:\n",
    "        sentence_weight = 0\n",
    "        for word in nltk.word_tokenize(sentence.lower()):\n",
    "            if word in word_frequencies.keys():\n",
    "                sentence_weight += word_frequencies[word]\n",
    "        sentence_weights[sentence] = sentence_weight\n",
    "\n",
    "    # Extract the top `num_sentences` sentences with the highest weights\n",
    "    summarized_sentences = heapq.nlargest(num_sentences, sentence_weights, key=sentence_weights.get)\n",
    "\n",
    "    # Join the extracted sentences into a single string\n",
    "    summary = \" \".join(summarized_sentences)\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(docx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def fuzzy_match(text, phrase, threshold=70):\n",
    "    score = fuzz.token_set_ratio(text, phrase)\n",
    "    return score >= threshold\n",
    "\n",
    "text = docx\n",
    "phrase = \"This is the bone of my bone\"\n",
    "\n",
    "if fuzzy_match(text, phrase):\n",
    "    print(\"Fuzzy match found!\")\n",
    "else:\n",
    "    print(\"Fuzzy match not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bible(resources):\n",
    "    df = pd.read_csv(resources)\n",
    "    return df\n",
    "bibles = [\"kjv\", \"dby\", \"asv\", \"bbe\", \"web\", \"wbt\", \"ylt\"]\n",
    "refs = [\"kjv_ref\", \"dby_ref\", \"asv_ref\", \"bbe_ref\", \"web_ref\", \"wbt_ref\", \"ylt_ref\"]\n",
    "\n",
    "for bible, ref in zip(bibles, refs):\n",
    "    locals()[bible] = load_bible(f\"resources/{bible}.csv\")\n",
    "    locals()[ref] = load_bible(f\"resources/{ref}.csv\")\n",
    "\n",
    "vs = load_bible(\"resources/bible_version_key.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locals()[bible]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install glob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
